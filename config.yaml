######################################################################
#                       PIPELINE DEFINITION
######################################################################
# what modules are we running
run:
     - dataset
     - run_pairs
     - dndz
     - compare
    #- compare_noz_fom    #NOT IMPLEMENTED YET [see Pauline's module on Github]



######################################################################
#                       verbose module
######################################################################
# verbose config:
# 0: print nothing
# 1: print only upon completing full item
# 2: print everything
verbose: 1


######################################################################
#                       data set module
######################################################################
# All inputs are read as dictionaries, so it is important to respect the
# identation. It produces the catalog "dataset_path_output", containing
# unknown and reference samples correctly binned for the paircounts.
# if "dataset_path_output" has already been computed, there is no need
# to run this module

dataset:

    #****************************************************************
    reference_data:
        path: input_files/specz_COSMOS.fits
        #table: catalog [for hdf5 files]
        file_format: fits
        columns:
            ra_column: RA                           # name of RA column
            dec_column: DEC                         # name of DEC column
            z_column: Z                             # name of Z column
            w_column: None                          # name of W column (not mandatory, could be set to None or erased)


    #****************************************************************
    reference_random:
        path: input_files/specz_COSMOS_random.fits
        file_format: fits
        columns:
            ra_column: RA                         # name of RA column
            dec_column: DEC                       # name of DEC column
            z_column: None                        # name of Z column (not mandatory for randoms, could be set to None or erased)
            w_column: None                        # name of W column (not mandatory for randoms, could be set to None or erased)

    #****************************************************************
    unknown_data:
        path: input_files/photoz_COSMOS_speczrestricted.fits
        file_format: fits
        columns:
            ra_column: RA                           # name of RA column
            dec_column: DEC                         # name of DEC colum
            z_photo_columns: ['Zphoto','Zphoto']             # name of photo Z columns
            w_column: None                          # name of W column (not mandatory for randoms, could be set to None or erased)


    #****************************************************************
    unknown_random:
        path: input_files/photoz_COSMOS_speczrestricted_random.fits
        file_format: fits
        columns:
            ra_column: RA                           # name of RA column
            dec_column: DEC                         # name of DEC colum
            z_column: None                          # name of photo Z column (not mandatory, could be set to None or erased)
            w_column: None                          # name of W column (not mandatory, could be set to None or erased)


    #****************************************************************
    # Binning in tomographic bins for the unknown
    unknown_bins:
          name_column: Zphoto           #Name of the column for  binning  the unknown in tomobins. It could be different than redshift (e.g. colors)

          #type: between               # if type: between, it creates the array with numpy.linspace. array has to be in the form [min,max,numbofbins].
          #array: [0.4,0.8,3]          # the array will be numpy.linspace(min,max,numbofbins+1,endpoint=True)
                                      # if type: equal, you have to provide the edges of your bins in array (e.g. :array: [0.1,0.2,0.3,0.6,1.0])
                                      #
          type: equal
          array: [0.2,0.43,0.63,0.9]


    reference_bins:                     #Name of the column for binning of the reference. It could be different than redshift
          name_column: Z
          type: between                 # the array will be numpy.linspace(min,max,numbofbins+1,endpoint=True)
          array: [0.2,1.0,12]           # the array will be numpy.linspace(min,max,numbofbins+1,endpoint=True)
                                        # if type: equal, you have to provide the edges of your bins in array (e.g. :array: [0.1,0.2,0.3,0.6,1.0])
          #type: equal
          #array: [0.1,0.2,0.3,0.5,1.0]

    #****************************************************************


    max_objects: 300000000                             # maximum number of
                                                      # objects in catalog
  #  label_every: 10000                                # when assigning bins,
                                                      # set the chunk size
  #  randoms_time: 2.                                  #if randoms are more numerous than randoms_time*len(data_catalog), it cuts them


    kind_regions: 'kmeans'                           # current kinds: 'kmeans' or 'healpix'
    number_of_regions: 80                            # if kind is kmeans, number_of_region is number of regions found by kmeans
                                                     # elif kind is healpix, number_of_region is the healpix nside
    load_regions: None                               # path to the jackknifes centers. Only for kmeans. it can be left to None


    dontsaveplot: False

######################################################################
#                       run pairs module
######################################################################
# commands for calculating paircounts
run_pairs:

    #This version computes the cross-correlation and the autocorrelation for a number of cases.
    #1) cross corr UNK-REF in angular bin
    #2) cross corr UNK-REF in angular bin corresponding to given physical distances
    #3) cross corr UNK-REF density (single bin estimation)
    #4) auto corr UNK in angular bin for the FULL sample
    #5) auto corr UNK in angular bin as a function of redshift. it uses z_true column to divide in bins.
    #6) auto corr REF in angular bin
    #7) auto corr REF in angular bin corresponding to given physical distances
    #8) auto corr REF  density (single bin estimation)
    #9) projected auto corr REF (physical distances)

    #names_output:                   label :           usage - Method: Menard/Alex        Menard physical        Newman       Schmidt
    #1) w_cross_angular_*            CC_A_                                 x       |           -           |      x     |       -
    #2) w_cross_physical_*           CC_P_                                 -       |           x           |      -     |       -
    #3) w_cross_density_*            CC_D_                                 -       |           -           |      -     |       x
    #4) w_auto_UNK_                  AC_U_                                 -       |           -           |      x     |       x
    #5) w_auto_UNK_*                 AC_U_P_                               -       |           x           |      x     |       x
    #6) w_auto_REF_angular_*         AC_R_A_                               x       |           -           |      -     |       -
    #7) w_auto_REF_physical_*        AC_R_P_                               -       |           x           |      x     |       x
    #8) w_auto_REF_density_*         AC_R_D_                               -       |           x           |      x     |       x
    #9) w_auto_REF_rp_*              AC_R_R_                               -       |           -           |      x     |       x


    #  if bias_correction_Menard == 1 or bias_correction_Menard == 2:
    #      Menard={'methods':['CC_A_','AC_R_A_']}
    #      Menard_physical_scales={'methods':['CC_P_','AC_R_P_']}
    #      Menard_physical_weighting={'methods':['CC_A_','AC_R_A_']}
    #  else:
    #      Menard={'methods':['CC_A_']}
    #      Menard_physical_scales={'methods':['CC_P_']}
    #      Menard_physical_weighting={'methods':['CC_A_']}


    #  if use_physical_scale_Newman:
    #      Newman={'methods':['CC_P_','AC_U_','AC_R_R_']}
    #  else:
    #      Newman={'methods':['CC_A_','AC_U_','AC_R_R_']}


    #  if bias_correction_Schmidt==3 :
    #      Schmidt={'methods':['CC_D_','AC_R_P_']}
    #  elif bias_correction_Schmidt==0 :
    #      Schmidt={'methods':['CC_D_']}
    #  elif bias_correction_Schmidt==4:
    #      Schmidt={'methods':['CC_D_','AC_R_D_']}
    #  elif bias_correction_Schmidt==5:
    #      Schmidt={'methods':['CC_D_','AC_R_P_','AC_U_P_']}
    #  else :
    #    Schmidt={'methods':['CC_D_','AC_U_','AC_R_R_']}

    tomo_bins: ['1','2','3']     # also 'ALL'

    overwrite: True             # if True, overwrite any existing files

    corr_tobecomputed: ['CC_P_'] #,'] #,'AC_R_P_']


    Nbins: [8]    #number of bins for the AC and CC.

    min_theta: 0.001   #[degrees] min separation for the angular CC and AC
    max_theta: 0.02    #[degrees] max separation for the angular CC and AC

    min_rp: 30.      #[kpc] min separation for the  CC and AC in physical distances
    max_rp: 100.     #[kpc] max separation for the  CC and AC in physical distances

    max_rpar: 80.     # [Mpc] #extrema of the integration for the projected autocorrelation


    cosmology: Planck15           #Accepted cosmology: Planck15,Planck13,WMAP9,WMAP7,WMAP5, FlatLambdaCDM
               ##  [FlatLambdaCDM]                  # For other cosmology modify directly in the dataset module: FlatLambdaCDM(H0=70, Om0=0.3)


    pairs : ['DD','DR']
    w_estimator: 'Natural_noRu'               # estimator for the w(theta) - just for plotting purposes : 'LS','Natural','Hamilton','Natural_noRu','Natural_noRr'
    number_of_cores: 4            # number of cores used in computing the pairs.

    jackknife_ring: False         #   it speeds up the computation when it comes to high number of jackknives.

    dontsaveplot: False
######################################################################
#                       dndz module
######################################################################
dndz:

    #  covariances guidelines:
    #  correlated subsamples bias the covariance low.
    #  ignoring pairs between patches biases the covariance high.

    #  jackknife, pairs=True : split half of the pairs among different regions when removing jk_th region
    #  jackknife, pairs=False : ignore  the pairs among different regions when removing jk_th region
    #  bootstrap, pairs=True :  half of the pairs among different regions are assigned to the bootstrapped jk_th region
    #  jackknife, pairs=False : ignore the pairs among different regions when bootstrapping the jk_th region



    resampling: bootstrap                # bootstrap or jackknife
    resampling_pairs: True               # resampling over pairs rather than galaxies
    number_of_bootstrap: 200             # number of bootstrap. Ingored in jackknife.



    photo_z_column: 'Zphoto'
    tomo_bins: ['1','2','3']         # also 'ALL'
    z_min: ['None','None','None']    #0.6 #'None'                   # z_min (>=)
    z_max: ['None','None','None']    #0.8 #'None'                   # z_max (<=)



    #  Methods used to compute the dndz.
    #  Options:
    #
    #    - 'ALL' : computes all the methods, with all the possible combinations of options (weight_variance,pairs_weighting)
    #    - 'RELIABLE' only Menard_physical_s,Newman,Schmidt, and various bias correction
    #    - 'Menard' :  dndz from cross-correlation computed at fixed angular scales
    #    - 'Menard_physical_scales':   dndz from cross-correlation computed at fixed physical scales
    #    - 'Menard_physical_weighting':   dndz from cross-correlation computed at fixed angular scales,
    #                                     but weighting scales with a factor of f(theta)= distance(theta(z))
    #    - 'Newman':   it uses the Newman method (fit the cross-correlation computed at fixed angular scales)
    #    - 'Schimdt' : it uses the Schmidt method (one bin estimation, counting pairs in anulus in physical scales)




    # ***  Methods options ****************************************************************************
    methods:  ['Menard_physical_scales']

    # options Menard only:
    bias_correction_Menard:  0   # 0 NO BIAS,
                                  # bias = 1 : N(z) and bias correction just with the 1-bin estimate from AC_R_P_
                                  # bias = 2 : divide by the autocorrelation before integrating
                                  # bias = 3 : N(z) and bias correction using 1-bin estimato for reference and unknown.

    weight_variance:  False       # minimum variance weighting [Menard method only]
    pairs_weighting:  False      # if set, it weights the pair counts (DD,DR,RD,RR) first. [Menard method only]

    # options Newman only:
    bias_correction_Newman: 1    # 0 NO BIAS, 1 , 2 . (default=1)
                                  # bias = 1: iterative procedure to estimate b_u; bias =2 : assumes b_u = b_r

    fit_free: True               # Newman: let the exponent of the cross correlation free in the fitting (defaul: False)
    use_physical_scale_Newman: True     # fit the CC in physical scales rather than angular scales (defaul: False)


    # options Schmidt only:
    bias_correction_Schmidt: 0    # 0 NO BIAS (standard), 1 , 2 , 3 , 4 , 5
                                  # bias = 1: iterative procedure to estimate b_u, a la Newman ; [noisy!]
                                  # bias = 2 : A la Newman correction, but assuming b_u = b_r ; [noisy!]
                                  # bias = 3: N(z) and bias correction just with the 1-bin estimate from AC_R_P_
                                  # bias = 4: N(z) and bias correction just with the 1-bin estimate from AC_R_D
                                  # bias = 5: N(z) and bias correction using 1-bin estimato for reference and unknown.


    # options Newman & Schmidt
    show_fit: True                # if true, it saves the fit for CC and AC


    # bounds format: [[min_amplitude, min_index, min_constant],[min_amplitude, min_index, min_constant]]
    # if fit_free=False, it will ignore the bounds and guess on the index of CC.

    bounds_CC_fit:        [[-1,1,-0.01],[1.,3, 0.01]]
    initial_guess_CC_fit: [0.01,2,0.01]
    bounds_AC_U_fit:       [[0.01,1,-0.01],[1.,3,0.01]]
    initial_guess_AC_U_fit: [0.01,2,0.01]
    bounds_AC_R_fit:       [[0.01,-1,-0.01],[200.,3,0.01]]
    initial_guess_AC_R_fit:  [2,1.5,0.01]

    # *** General options ****************************************************************************


    w_estimator: 'Natural_noRu'             # which estimator to use for the w(theta)



    only_diagonal:  True          # when it comes to compute statistics, it considers only the diagonal.
    verbose:  False

    # ***  Optimization options ****************************************************************************

    optimization:  False              # if false, it doesn't perform the scales optimization
    Nbins:  [8]                           # angular bins (they should be the same of run_pairs module)
    interval_width: 3.                    # parameter for the optimization of scales
    step_width: 6.                        # parameter for the optimization of scales

    # ***  Regularizations options  **************************************************************************
    # this will apply only to the dndz with and without bias correction that have proven to have the best S/N

    regularization: False                           # if set, it will correct for negative point and fit the dndz
    set_negative_to_zero:  fixed                     # set negative values to zero; none, fixed, mcmc
    fit: None                           # choose between None, gaussian_processes
    prior_gaussian_process: None    #[1.53689698e+04  , 1.68542771e-01]

# *****************************************************************************************************************************



###############################################################################
#                               COMPARE MODULE
###############################################################################

# compare takes input n(z) and does simple redshift bias model fitting
compare:

    label_output: 'Menard_boot200'

    tomo_bins: ['1','2','3']  #tomobins as assumed in the dataset file.

    photo_z_columns: ['Zphoto','Zphoto']  #   it will avergae the photo-z predictions over these columns
    true_column:     'Zphoto'           #   it will compute the residual shifts over this

    path_wz_samples: ['./output_dndz/TOMO_1/best_Nz/NZ_Menard_physical_scales____bootstrap_pairs_200','./output_dndz/TOMO_2/best_Nz/NZ_Menard_physical_scales____bootstrap_pairs_200','./output_dndz/TOMO_3/best_Nz/NZ_Menard_physical_scales____bootstrap_pairs_200']

    path_datasets: ['./pairscount/','./pairscount/','./pairscount/']

    # priors ******************************************************************************
    #
    # priors have to be in the form of priors: {'tomo1': priors_tomo1, 'tomo2': priors_tomo2 ... 'tomoN': priors_tomoN, 'gamma': gamma}.
    # gamma can be omitted. for each tomobin, you can set the priors on shift,amplitude, and spread. omitting one of them will cause the code
    # to ignore the parameter in the MCMC
    #
    #

    priors: {'photo_z1' : {
                          # 1ST TOMOGRAPHIC BIN ************
                          'tomo1' : {'deltaz': {'kind': 'truncnorm', 'weight': 1,'kwargs': {'a': -5.0, 'b': 5.0,'loc': 0.0, 'scale': 0.05}},
                                    'amplitude' : {'kind': 'truncnorm', 'weight': 1,'kwargs': {'a': -5.0, 'b': 5.0,'loc': 0, 'scale': 1.}}}, #,
                                    #'spread': {'kind': 'uniform', 'weight': 1,'kwargs': {'loc': 1., 'scale': 0.00000001}}}

                          # 2ND TOMOGRAPHIC BIN ************
                          'tomo2' : {'deltaz': {'kind': 'truncnorm', 'weight': 1,'kwargs': {'a': -5.0, 'b': 5.0,'loc': 0.0, 'scale': 0.05}},
                                    'amplitude'  : {'kind': 'truncnorm', 'weight': 1,'kwargs': {'a': -5.0, 'b': 5.0,'loc': 0, 'scale': 1.}}}, #,
                                    #'spread': {'kind': 'uniform', 'weight': 1,'kwargs': {'loc': 1., 'scale': 0.00000001}}}

                          # 3RD TOMOGRAPHIC BIN ************
                          'tomo3' : {'deltaz': {'kind': 'truncnorm', 'weight': 1,'kwargs': {'a': -5.0, 'b': 5.0,'loc': 0.0, 'scale': 0.05}},
                                    'amplitude' : {'kind': 'truncnorm', 'weight': 1,'kwargs': {'a': -5.0, 'b': 5.0,'loc': 0, 'scale': 1.}}}}, #, #,
                                    #'spread': {'kind': 'uniform', 'weight': 1,'kwargs': {'loc': 1., 'scale': 0.00000001}}}

             'photo_z2' : {
                          # 1ST TOMOGRAPHIC BIN ************
                            'tomo1' : {'deltaz': {'kind': 'truncnorm', 'weight': 1,'kwargs': {'a': -5.0, 'b': 5.0,'loc': 0.0, 'scale': 0.05}},
                                      'amplitude' : {'kind': 'truncnorm', 'weight': 1,'kwargs': {'a': -5.0, 'b': 5.0,'loc': 0, 'scale': 1.}}}, #,
                                      #'spread': {'kind': 'uniform', 'weight': 1,'kwargs': {'loc': 1., 'scale': 0.00000001}}}

                        # 2ND TOMOGRAPHIC BIN ************
                            'tomo2' : {'deltaz': {'kind': 'truncnorm', 'weight': 1,'kwargs': {'a': -5.0, 'b': 5.0,'loc': 0.0, 'scale': 0.05}},
                                      'amplitude'  : {'kind': 'truncnorm', 'weight': 1,'kwargs': {'a': -5.0, 'b': 5.0,'loc': 0, 'scale': 1.}}}, #,
                                      #'spread': {'kind': 'uniform', 'weight': 1,'kwargs': {'loc': 1., 'scale': 0.00000001}}}

                        # 3RD TOMOGRAPHIC BIN ************
                             'tomo3' : {'deltaz': {'kind': 'truncnorm', 'weight': 1,'kwargs': {'a': -5.0, 'b': 5.0,'loc': 0.0, 'scale': 0.05}},
                                      'amplitude' : {'kind': 'truncnorm', 'weight': 1,'kwargs': {'a': -5.0, 'b': 5.0,'loc': 0, 'scale': 1.}}}}, #, #,
                                    #'spread': {'kind': 'uniform', 'weight': 1,'kwargs': {'loc': 1., 'scale': 0.00000001}}}
            }
    # **************************************************************************************
    sigma: 'all'            #this selects wz dndz only in the interval mean(wz) +- sigma *std. all option available
    zmin: 'None'
    zmax: 'None'
    add_noise: False         #it adds random noise to the true distribution (for sims only and photoz)

    shift_pz_1: [0.,0.,0.]          #this applies a shift to the true distribution beforehand
    model_kwargs: {'z0': 0.5}

    resampling: bootstrap
    # mcmc options **************************************

    cov_mode: 'diag'
    nwalkers: 10
    nburnin: 20
    nrun: 30
    live_dangerously: False,
